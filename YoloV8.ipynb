{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpU0K6jbFb2O"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFo7aGQXzfcn"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFLKMILiHqGb"
      },
      "outputs": [],
      "source": [
        "%cd /content/ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJvIvQlsH6JE"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtTMJD-fuRZ_"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m50ihGN4wgqp"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOc53zROujXQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def estimate_distance(x1, y1, x2, y2,focal_length):\n",
        "\n",
        "    h = y2-y1\n",
        "\n",
        "\n",
        "    car_height_mm = 1500  # Example vehicle width in millimeters\n",
        "    truck_height_mm = 3000\n",
        "\n",
        "    focal_length_pixels = focal_length\n",
        "\n",
        "    # Estimate the distance based on the width of the bounding box in pixels\n",
        "\n",
        "\n",
        "    return (car_height_mm * focal_length_pixels) / h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQxLhuGL5Le6"
      },
      "outputs": [],
      "source": [
        "def draw_bounding_box_with_label(image, x1, y1, x2, y2, label, color, thickness=1):\n",
        "    # draw bounding box\n",
        "    cv2.rectangle(image, (x1, y1), (x2, y2), color=color, thickness=thickness)\n",
        "    # draw a rectangle that contains label\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 0.7\n",
        "    label_size, baseline = cv2.getTextSize(label, font, font_scale, thickness=thickness)\n",
        "    cv2.rectangle(\n",
        "        image,\n",
        "        (x1 - int(thickness / 2), y1 - label_size[1]),\n",
        "        (x1 + label_size[0], y1),\n",
        "        color,\n",
        "        cv2.FILLED,\n",
        "    )\n",
        "    # draw label\n",
        "    cv2.putText(\n",
        "        image, label, (x1, y1), font, font_scale, color=(0, 0, 0)\n",
        "    )  # black label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1n1qQbeooVDVJ44yW2iG-Mu9iMCYp85z0/view?usp=sharing"
      ],
      "metadata": {
        "id": "dxd8EMDuNVDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74eqIqlptCiR"
      },
      "outputs": [],
      "source": [
        "# !pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqzEp6epwLwe"
      },
      "outputs": [],
      "source": [
        "# from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "\n",
        "# clip = VideoFileClip(\"/content/highway05.mp4\").subclip(0, 10) # Trim video from 0 to 10 seconds\n",
        "\n",
        "# clip.write_videofile(\"/content/trimmed_video.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/focal.png'"
      ],
      "metadata": {
        "id": "5VfyNQ19KXCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.predict(image_path, stream=True,show=True)\n",
        "for result in results:\n",
        "  boxes = result.boxes[0].cpu().numpy()\n",
        "  for box in boxes:                                          # iterate boxes\n",
        "      r = box.xyxy[0].astype(int)                            # get corner points as int\n",
        "      print(r)\n",
        "      x1,y1,x2,y2 = r\n"
      ],
      "metadata": {
        "id": "3FV92tgsOLsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image =cv2.imread(image_path)\n",
        "for result in results:\n",
        "  boxes = result.boxes[0].cpu().numpy() # get boxes on cpu in numpy\n",
        "  for box in boxes: # iterate boxes\n",
        "   r = box.xyxy[0].astype(int) # get corner points as int\n",
        "print(r) # print boxes\n",
        "cv2.rectangle(image, r[:2], r[2:], (0,255,0), 2) # draw boxes on img"
      ],
      "metadata": {
        "id": "kBkpSeKHhEzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "TNDgaDXWiD5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_focal_length(x1,x2,y1,y2):\n",
        "  height_bbox = y2-y1\n",
        "\n",
        "  obj_height = 1700\n",
        "\n",
        "  distance_mm = 3600\n",
        "\n",
        "  return (height_bbox * distance_mm)/obj_height"
      ],
      "metadata": {
        "id": "wk2pFRi5R_KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "focal_length = calc_focal_length(x1,x2,y1,y2)\n",
        "print(focal_length)"
      ],
      "metadata": {
        "id": "NCKC9FN-TwCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjwv7FMPvrL_"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1KTDY-DwZ9nKHVDfDMA1ZsOse9SHYPch_/view?usp=drive_link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eIX_xckIs3E"
      },
      "outputs": [],
      "source": [
        "# Open the video file\n",
        "video_path = \"/content/cam02.avi\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_rate = cap.get(cv2.CAP_PROP_FPS)  # Get the frame rate of the video\n",
        "print(frame_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hSLqc6C9u1c"
      },
      "outputs": [],
      "source": [
        "# Define the output video path and properties\n",
        "output_video_path = \"/content/output_video.mp4\"\n",
        "output_video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "output_video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "output_video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Create a VideoWriter object to save the processed frames\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
        "output_video = cv2.VideoWriter(output_video_path, fourcc, output_video_fps, (output_video_width, output_video_height))\n",
        "\n",
        "# Define a dictionary to store the previous distances for each object\n",
        "previous_distances = {}\n",
        "previous_frames = {}\n",
        "frame_rate = cap.get(cv2.CAP_PROP_FPS)  # Get the frame rate of the video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkAqbcnreLlm"
      },
      "source": [
        "Xe trước tăng tốc: pre_dis < dis -> dis_dap > 0\n",
        "\n",
        "Xe trước giảm tốc: pre_dis > dis -> dis_gap = p.dis - dis < 0\n",
        "\n",
        "speed = camera_speed + (distance_gap / time_gap)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5BPQEyz9vmh"
      },
      "outputs": [],
      "source": [
        "frame_list = []\n",
        "frame_limit = 5\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, frame = cap.read()\n",
        "    if success:\n",
        "        results = model.track(frame, stream=True, conf=0.25, classes=[2], tracker=\"botsort.yaml\")\n",
        "        for result in results:\n",
        "            boxes = result.boxes.cpu().numpy()\n",
        "            for box in boxes:\n",
        "                r = box.xyxy[0].astype(int)\n",
        "                x1, y1, x2, y2 = r\n",
        "\n",
        "                if box.id is None:\n",
        "                    box_id = 0\n",
        "                else:\n",
        "                    box_id = int(box.id)\n",
        "                box_id_tuple = tuple([box_id])\n",
        "\n",
        "                # Estimate distance in meters\n",
        "                capo_width = 1\n",
        "                distance = estimate_distance(x1, y1, x2, y2, focal_length) / 1000 - capo_width\n",
        "\n",
        "                # Check if the object has a previous distance stored\n",
        "                if box_id_tuple in previous_distances:\n",
        "                    # Retrieve the previous distance\n",
        "                    previous_distance = previous_distances[box_id_tuple]\n",
        "\n",
        "                    # Calculate the distance gap\n",
        "                    distance_gap = distance - previous_distance\n",
        "\n",
        "                    # Calculate the time gap in seconds\n",
        "                    time_gap = 1 / frame_rate  # Assuming the frame rate is constant\n",
        "\n",
        "                    camera_speed = 50 / 3.6  # m/s\n",
        "                    # Calculate the speed of infront of car in m/s\n",
        "                    speed = camera_speed + (distance_gap / time_gap)\n",
        "\n",
        "                    label = f\"car{box_id}: {distance:.1f}m ({distance_gap:.2f}m) speed:{speed:.1f}m/s\"\n",
        "                    color = (0, 255, 0)\n",
        "\n",
        "                    draw_bounding_box_with_label(frame, x1, y1, x2, y2, label=label, color=color)\n",
        "\n",
        "                # Save the current distance as the previous distance for the object\n",
        "                previous_distances[box_id_tuple] = distance\n",
        "\n",
        "                frame_list.append(frame)\n",
        "\n",
        "                if len(frame_list) > frame_limit:\n",
        "                    old_frame = frame_list.pop(0)\n",
        "                    # Thực hiện các thao tác với frame đầu tiên (old_frame)\n",
        "                    # ...\n",
        "\n",
        "                frame_count += 1\n",
        "\n",
        "                if frame_count == frame_limit:\n",
        "                    # Tính giá trị trung bình của 5 frame\n",
        "                    # ...\n",
        "\n",
        "                    # Cập nhật giá trị mới cho 5 frame\n",
        "                    # ...\n",
        "\n",
        "                    # Đặt lại biến đếm frame\n",
        "                    frame_count = 0\n",
        "\n",
        "        output_video.write(frame)\n",
        "\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "output_video.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62K5FcShJaXl"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os\n",
        "\n",
        "input_path = \"/content/output_video.mp4\"\n",
        "compress_path = \"/content/result.mp4\"\n",
        "\n",
        "os.system(f\"ffmpeg -i {input_path} -vcodec libx264 {compress_path}\")\n",
        "\n",
        "mp4 = open(compress_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width 500 controls>\n",
        "  <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" %data_url)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}